S_x2x2 <- sum(x1^2)-((sum(x1)^2)/100)
S_x1x2 <- sum(x1*x2) - ((sum(x1)*sum(x2))/100)
S_x1x1 <- sum(x1^2)-((sum(x1)^2)/100)
S_x2x2 <- sum(x2^2)-((sum(x2)^2)/100)
S_x1x2 <- sum(x1*x2) - ((sum(x1)*sum(x2))/100)
S_x1y <-sum(x1*y) - ((sum(x1)*sum(y))/100)
S_x2y <-sum(x2*y) - ((sum(x2)*sum(y))/100)
((S_x2y*S_x1x1)-(Sx1y*Sx1x2))/(S_x1x1*S_x2x2 - (S_x1x2)^2)
S_x1y <-sum(x1*y) - ((sum(x1)*sum(y))/100)
S_x2y <-sum(x2*y) - ((sum(x2)*sum(y))/100)
S_x1y
((S_x2y*S_x1x1)-(S_x1y*S_x1x2))/(S_x1x1*S_x2x2 - (S_x1x2)^2)
b2 = ((S_x2y*S_x1x1)-(S_x1y*S_x1x2))/(S_x1x1*S_x2x2 - (S_x1x2)^2)
1/8
b2 <- ((S_x2y*S_x1x1)-(S_x1y*S_x1x2))/(S_x1x1*S_x2x2 - (S_x1x2)^2)
b1 <- (S_x1y-b2*S_x1x2)/S_x1x2
b1
b1 <- (S_x1y-b2*S_x1x2)/S_x1x1
b1
5/34
5/3
weight <- round(runif(10, min = 2, max = 10), 1)
weight
weight <- round(runif(10, min = 2, max = 10), 1)
weight <- sort(weight)
weight
size <- 2 + weight * 2.3 + rnorm(10, 0, 1)
size
size <- round(2 + weight * 2.3 + rnorm(10, 0, 1), 1)
size
size_biased <- round(2 + weight * 2.7 + rnorm(10, 0, 1), 1)
size_biased
library(tidyverse)
df <- tibble(weight, size, size_biased)
df
size <- round(2 + weight * 2.3 + rnorm(10, 0, 2), 1)
size_biased <- round(2 + weight * 2.7 + rnorm(10, 0, 2), 1)
df <- tibble(weight, size, size_biased)
df
df %>%
pivot_longer(size:size_biased)
df %>%
pivot_longer(size:size_biased) %>%
ggplot(aes(x = weight, y = value, color = name)) +
geom_point()
df %>%
pivot_longer(size:size_biased) %>%
ggplot(aes(x = weight, y = value, color = name)) +
geom_point() +
geom_smooth(method = "lm")
df %>%
pivot_longer(size:size_biased) %>%
ggplot(aes(x = weight, y = value, color = name)) +
geom_point() +
geom_smooth(method = "lm", formula = "y ~ x")
?geom_smooth()
size <- round(2 + weight * 1.3 + rnorm(10, 0, 2), 1)
size_biased <- round(2 + weight * 2.7 + rnorm(10, 0, 2), 1)
df <- tibble(weight, size, size_biased)
df %>%
pivot_longer(size:size_biased) %>%
ggplot(aes(x = weight, y = value, color = name)) +
geom_point() +
geom_smooth(method = "lm", formula = "y ~ x", se = F)
size_biased <- round(0.5 + weight * 2.7 + rnorm(10, 0, 2), 1)
df <- tibble(weight, size, size_biased)
df %>%
pivot_longer(size:size_biased) %>%
ggplot(aes(x = weight, y = value, color = name)) +
geom_point() +
geom_smooth(method = "lm", formula = "y ~ x", se = F)
size_biased <- round(-1 + weight * 2.7 + rnorm(10, 0, 2), 1)
df <- tibble(weight, size, size_biased)
df %>%
pivot_longer(size:size_biased) %>%
ggplot(aes(x = weight, y = value, color = name)) +
geom_point() +
geom_smooth(method = "lm", formula = "y ~ x", se = F)
size_biased <- round(-2 + weight * 2.7 + rnorm(10, 0, 2), 1)
df <- tibble(weight, size, size_biased)
df %>%
pivot_longer(size:size_biased) %>%
ggplot(aes(x = weight, y = value, color = name)) +
geom_point() +
geom_smooth(method = "lm", formula = "y ~ x", se = F)
size_biased <- round(-3 + weight * 2.7 + rnorm(10, 0, 2), 1)
df <- tibble(weight, size, size_biased)
df %>%
pivot_longer(size:size_biased) %>%
ggplot(aes(x = weight, y = value, color = name)) +
geom_point() +
geom_smooth(method = "lm", formula = "y ~ x", se = F)
weight <- round(runif(10, min = 2, max = 10), 1)
weight <- sort(weight)
size <- round(2 + weight * 1.3 + rnorm(10, 0, 2), 1)
size
weight <- round(runif(5, min = 2, max = 10), 1)
weight <- sort(weight)
size <- round(2 + weight * 2.1 + rnorm(10, 0, 3), 1)
lm(weight ~ size)
weight <- round(runif(20, min = 2, max = 10), 1)
weight <- sort(weight)
weight <- sort(weight)
size <- round(2 + weight * 2.1 + rnorm(20, 0, 3), 1)
size
weight*2.1
sort(2 + weight*2.1)
sort(2 + weight*2.1)
size
weight <- round(runif(20, min = 2, max = 10), 1)
weight <- sort(weight)
size <- round(2 + weight * 2.1 + rnorm(20, 0, 3), 1)
df <- tibble(weight, size)
tibble
df
df %>%
mutate(size_theoret = 2+weight*2.1)
weight <- round(runif(20, min = 2, max = 10), 1)
weight <- sort(weight)
size <- round(2 + weight * 2.1 + rnorm(20, 0, 3), 1)
df <- tibble(weight, size)
df %>%
mutate(size_theoret = 2+weight*2.1)
df %>%
mutate(size_theoret = 2+weight*2.1) %>%
filter(size > size_theoret)
df %>%
mutate(size_theoret = 2+weight*2.1) %>%
filter(size > size_theoret) %>%
pull(weight)
biased_weight <- df %>%
mutate(size_theoret = 2+weight*2.1) %>%
filter(size > size_theoret) %>%
pull(weight)
biased_size <- df %>%
mutate(size_theoret = 2+weight*2.1) %>%
filter(size > size_theoret) %>%
pull(size)
lm(size ~ weight)
lm(biased_size ~ biased_weight)
weight <- round(runif(100, min = 2, max = 10), 1)
weight <- sort(weight)
size <- round(2 + weight * 2.1 + rnorm(20, 0, 3), 1)
df <- tibble(weight, size)
df
weight <- round(runif(100, min = 2, max = 20), 1)
weight <- sort(weight)
size <- round(2 + weight * 2.1 + rnorm(20, 0, 3), 1)
df <- tibble(weight, size)
df %>%
mutate(size_theoret = 2+weight*2.1) %>%
filter(size > size_theoret)
?sample_n
biased_df <- df %>%
mutate(size_theoret = 2+weight*2.1) %>%
filter(size > size_theoret) %>%
sample_n(10) %>%
select(size, weight)
df
biased_df
lm(biased_df$size ~ biased_df$weight)
lm(df$size ~ df$weight)
lm(biased_df$size ~ biased_df$weight)
biased_df
biased_df %>%
mutate(slope_1.6 = 2+1.6*weight)
biased_df %>%
mutate(slope_1.6 = 2+1.6*weight,
slope_1.8 = 2+1.8*weight,
slope_2.0 = 2+2*weight)
biased_df %>%
mutate(slope_1.6 = 2+1.6*weight,
slope_1.8 = 2+1.8*weight,
slope_2.0 = 2+2*weight,
slope_2.2 = 2+2*weight)
biased_df %>%
mutate(slope_1.6 = 2+1.6*weight,
slope_1.8 = 2+1.8*weight,
slope_2.0 = 2+2*weight,
slope_2.2 = 2+2*weight) %>%
pivot_longer(slope_1.6:slope_2.2)
biased_df %>%
mutate(slope_1.6 = 2+1.6*weight,
slope_1.8 = 2+1.8*weight,
slope_2.0 = 2+2*weight,
slope_2.2 = 2+2*weight) %>%
pivot_longer(slope_1.6:slope_2.2) %>%
mutate(ssres = (size-value)^2)
biased_df %>%
mutate(slope_1.6 = 2+1.6*weight,
slope_1.8 = 2+1.8*weight,
slope_2.0 = 2+2*weight,
slope_2.2 = 2+2*weight) %>%
pivot_longer(slope_1.6:slope_2.2) %>%
mutate(ssres = sum((size-value)^2))
biased_df %>%
mutate(slope_1.6 = 2+1.6*weight,
slope_1.8 = 2+1.8*weight,
slope_2.0 = 2+2*weight,
slope_2.2 = 2+2*weight) %>%
pivot_longer(slope_1.6:slope_2.2) %>%
mutate(ssres = sum((size-value)^2)) %>%
select(ssres, name) %>%
distinct()
biased_df %>%
mutate(slope_1.6 = 2+1.6*weight,
slope_1.8 = 2+1.8*weight,
slope_2.0 = 2+2*weight,
slope_2.2 = 2+2*weight) %>%
pivot_longer(slope_1.6:slope_2.2) %>%
mutate(sres = (size-value)^2) %>%
group_by(name) %>%
mutate(ssres = sum(sres))
biased_df %>%
mutate(slope_1.6 = 2+1.6*weight,
slope_1.8 = 2+1.8*weight,
slope_2.0 = 2+2*weight,
slope_2.2 = 2+2*weight) %>%
pivot_longer(slope_1.6:slope_2.2) %>%
mutate(sres = (size-value)^2) %>%
group_by(name) %>%
mutate(ssres = sum(sres)) %>%
ungroup() %>%
select(size, ssres, name) %>%
distinct()
biased_df %>%
mutate(slope_1.6 = 2+1.6*weight,
slope_1.8 = 2+1.8*weight,
slope_2.0 = 2+2*weight,
slope_2.2 = 2+2*weight) %>%
pivot_longer(slope_1.6:slope_2.2) %>%
mutate(sres = (size-value)^2) %>%
group_by(name) %>%
mutate(ssres = sum(sres)) %>%
ungroup() %>%
select(ssres, name) %>%
distinct()
weight <- round(runif(10, 3, 8), 1)
wegiht
weight
weight <- sort(round(runif(10, 3, 8), 1))
(weight <- sort(round(runif(10, 3, 8), 1)))
(size <- -1 + 1.5*weight + rnorm(10, 0, 1))
(round(size <- -1 + 1.5*weight + rnorm(10, 0, 1), 1))
(size <- round(-1 + 1.5*weight + rnorm(10, 0, 1), 1))
size
weight
#### Simple Example of Lasso and Ridge Regression ####
set.seed(22)
# Predicting mouse size from weight #
(weight <- sort(round(runif(10, 3, 8), 1)))
# Let the relationship between weight and size be: size = -1 + 1.5*weight + error
(size <- round(-1 + 1.5*weight + rnorm(10, 0, 1), 1))
# Tibble of data, select observations greater than predicted line
(df <- tibble(size, weight))
library(tidyverse)
#### Simple Example of Lasso and Ridge Regression ####
library(tidyverse)
set.seed(22)
# Predicting mouse size from weight #
(weight <- sort(round(runif(10, 3, 8), 1)))
# Let the relationship between weight and size be: size = -1 + 1.5*weight + error
(size <- round(-1 + 1.5*weight + rnorm(10, 0, 1), 1))
# Tibble of data, select observations greater than predicted line
(df <- tibble(size, weight))
lm(size ~ weight)
coef(lm(size ~ weight))
coef(lm(size ~ weight))[[1]]
vector_est <- coef(lm(size ~ weight))
df
df %>%
mutate(size_pred = weight * coef[[2]] + coef[[1]])
lm_est <- coef(lm(size ~ weight))
df %>% mutate(size_pred = weight * lm_est[[2]] + lm_est[[1]])
df <- df %>% mutate(size_pred = weight * lm_est[[2]] + lm_est[[1]])
(df <- df %>% mutate(size_pred = weight * lm_est[[2]] + lm_est[[1]]))
df
df
(df %>% filter(size > size_pred))
installr::updateR()
wd <- "C:/Users/jhsau/OneDrive/Desktop/Documents/GitHub/CHL5250/"
setwd(wd)
library(haven)
library(naniar)
library(gtsummary)
library(pROC)
library(dplyr)
library(caret)
library(polycor)
library(tidyr)
library(Hmisc)
library(mice)
library(here)
library(knitr)
library(glmnet)
library(rstanarm)
frax_risk <- read_sas(here("data","frax_risk.sas7bdat"), NULL)
frax_risk <- as.data.frame(frax_risk)
# Clean Data ----------------------------------------------------------------------------------------------
# To do: 1. try split-rule (default was 'gini' which isn't good for continuous)
#        2. further investigation of <NA>s https://github.com/imbs-hl/ranger/issues/201
#        3. Shared group doc questions
library(tidyverse)
library(caret)
library(randomForest)
library(ranger)
frax_risk <- tibble::as_tibble(read_sas(here("data","frax_risk.sas7bdat"), NULL))
# * Remove "Don't Know" values, etc. ----
## Variables take values '99999', '7777', etc. for "Don't Know", "Refused"
## Set all of these values to NA
frax_risk_na_edit <- frax_risk %>%
pivot_longer(!c(SEQN, RIDAGEYR)) %>%
mutate(value = if_else(value %in% c("9", "7", "99", "77", "999", "777", "9999", "7777", "99999", "77777"), NA_real_, value)) %>%
pivot_wider(names_from = "name", values_from = "value")
# * Compare methods of replacment ----
dn <- c("MCQ160L","MCQ160A","ALQ101","DBQ197","DBQ229","DIQ010","DIQ220","MCQ190",
"MCQ160C","OSQ010A","OSQ010B","OSQ010C","OSQ040AA","OSQ040BA","OSQ040CA",
"OSQ070","OSQ130","OSQ170","OSQ200","OSQ140U","SMQ020", "ALQ130","ALQ140Q",
"DID040","OSQ140Q","OSQ020A","OSQ020B","OSQ020C","WHD020","WHD110","WHD010",
"MCQ160A","MCQ180A","MCQ180C","MCQ160L","MCQ170L","MCQ180L")
frax_risk %>%
pivot_longer(!c(SEQN, RIDAGEYR)) %>%
filter(value %in% c("9", "7", "99", "77", "999", "777", "9999", "7777", "99999", "77777")) %>%
select(name, value) %>%
distinct() %>%
filter(!name %in% dn) # SMQ040 is not present in the standard method?
rm(dn)
# * Recode Ethnicity
# https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx?BeginYear=2007
# Coding is: 1 - white, 2 - black, 3 - other
frax_risk_na_edit <- frax_risk_na_edit %>%
mutate(RIDRETH1 = case_when(
is.na(RIDRETH1) ~ NA_real_,
RIDRETH1 == 3 ~ 1,
RIDRETH1 == 4 ~ 2,
TRUE ~ 3
))
# * Remove sampling info ----
# Remove three columns that contain sampling information
# The three columns are: WTMEC2YR, SDMVPSU, SDMVSTRA
# WTMEC2YR: full 2 year sample weight
# SDMVPSU: Masked variance pseudo PSU for variance estimation
# SDMVSTRA: Masked variance unit pseudo-stratum variable for variance estimation
# https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2008002/article/10759-eng.pdf?st=dmkcZauV
frax_risk_na_edit <- frax_risk_na_edit %>% select(-c(WTMEC2YR, SDMVPSU, SDMVSTRA))
# * Select Col <= 40% NA ----
# The data frame contains many NA values
# Select only columns that do not have > 40% NA
df <- frax_risk_na_edit[,which(colMeans(is.na(frax_risk_na_edit)) <= 0.4)]
# * Create sensitivity analysis ----
# Create a dataframe (to be used later) for sensitivity analysis
# which contains absolutely no NAs
# Note that this filter was on a dataset with columns <= 0.40 NAs
complete_frax <- na.omit(df)
# * Remove rows with NA in any of the three fracture ----
# cols; cannot be used in prediction because we don't know if
# they've experience a fracture or not
df <- df %>% filter(!(is.na(OSQ010A) | is.na(OSQ010B) | is.na(OSQ010C)))
# * * * * * PROBLEM: Remove NZV & Correlated Cols ----
# Wait to hear back from group RE: method of imputation pre/post NZV removal
# WHD010: no info, WHD020: current weight, WHD110: self-reported weight 10 yrs ago
df <- df %>% select(-c(SEQN, WHD010, WHD020, WHD110))
formla <- as.formula(paste(" ~ ", paste(colnames(df), collapse=" +")))
impute_arg <- aregImpute(formula = formla, data = df, n.impute = 10, nk = 0)
rm(formla)
# * Get imputed dataframe ----
# Use pkg:mice to impute missing data, reformat into a dataframe
impute <- impute.transcan(impute_arg, data = df, imputation = 1, list.out = TRUE, pr = FALSE, check = FALSE)
impute <- as_tibble(do.call(cbind, impute))
rm(impute_arg, df)
# * Add proper names ----
impute <- impute %>%
rename(age = RIDAGEYR, sex = RIAGENDR, ethnicity = RIDRETH1,
frac_hip = OSQ010A, frac_wrist = OSQ010B, frac_spine = OSQ010C,
steroids = OSQ130, mother_frac_hip = OSQ170, father_frac_hip = OSQ200, cigarettes = SMQ020,
alcohol = ALQ101, diabetes = DIQ010, arthritis = MCQ160A, chd = MCQ160C, liver = MCQ160L,
bmd_femur = DXXOFBMD, bmd_neck = DXXNKBMD, bmd_troch = DXXTRBMD, bmd_intertroch = DXXINBMD,
bmd_ward = DXXWDBMD, bmd_L1 = DXXL1BMD, bmd_L2 = DXXL2BMD, bmd_L3 = DXXL3BMD, bmd_L4 = DXXL4BMD,
bmd_spine = DXXOSBMD, milk_30days = DBQ197, milk_5times = DBQ229, bmi = BMXBMI)
# * Create fracture indicator ----
impute <- impute %>% mutate(frac = if_else(frac_hip == 1 | frac_wrist == 1 | frac_spine == 1, 1, 0))
# * Get BMD column names ----
bmd_colnames <- impute %>% select(contains("bmd")) %>% colnames()
# * Order column names ----
# Easier to change column format & more sensible to have
# outcome come first; continuous vars set last
impute <- impute %>%
relocate(bmd_femur:bmd_L4, .after = last_col()) %>%
relocate(c(frac, frac_hip:frac_spine), .before = age) %>%
relocate(c(age, bmi), .after = milk_5times)
# Random Forest ---------------------------------------------------------------
# * Data Setup ----
# Get vector of column names that should be factors
# Then apply mutate to this vector
impute <- impute %>% mutate(across(c(frac:milk_5times), ~ as.factor(.x)))
#impute <- impute %>% mutate(frac = as.factor(frac))
# * Primary Objective: Fracture Predictors ----
# Must remove frac_hip:frac_wrist because
# we are predicting total fracture
rf_q1_data <- impute %>% select(-c(frac_hip:frac_spine))
library(caret)
library(recipes)
library(modeldata)
impute2 <- impute %>%
mutate(frac = factor(if_else(frac == "1", "yes", "no"))) %>%
select(-c(frac_hip:frac_spine)) %>%
mutate(across(sex:milk_5times, ~ as.factor(paste0("fn", .x))))
knn_q1_data <- rsample::initial_split(impute2, prop = 0.7, strata = "frac", seed = 5050)
knn_q1_data_train <- rsample::training(knn_q1_data)
# Create model blueprint
blueprint <- recipe(frac ~ ., data = knn_q1_data_train) %>%
# step_nzv(all_nominal()) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors(), one_hot = T)
# Create resampling method
boot <- trainControl(
method = "boot",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary
)
# Hypergrid of parameters
hyper_grid <- expand.grid(
k = c(100, 300, 500)
)
# KNN model, grid search
knn_grid <- train(
blueprint,
data = knn_q1_data_train,
method = "knn",
trControl = boot,
tuneGrid = hyper_grid,
metric = "ROC"
)
# Hypergrid of parameters
hyper_grid <- expand.grid(
k = c(101, 301, 501)
)
# KNN model, grid search
knn_grid <- train(
blueprint,
data = knn_q1_data_train,
method = "knn",
trControl = boot,
tuneGrid = hyper_grid,
metric = "ROC"
)
?knn()
knn_q1_data_test <- rsample::testing(knn_q1_data)
knn(knn_q1_data_train, knn_q1_data_test, k = 180, l = 0, prob = T)
sessionInfo()
?caret::knn3
knn3(frac ~ ., data = knn_q1_data_train, k = 180, l = 0, prob = T)
knn3(train = knn_q1_data_train, test = knn_q1_data_test, k = 180, l = 0, prob = T)
knn_q1_data_train
knn3(frac ~ ., knn_q1_data_train, k = 180, l = 0, prob = T)
v <- knn3(frac ~ ., knn_q1_data_train, k = 180, l = 0, prob = T)
v
v$theDots
v$k
predict(v, knn_q1_data_test, type = "class")
sample(c(1, 0), size = 100, replace = T)
x <- runif(100, 2, 10)
x
?sample()
y_jiayin <- sample(c(1,0), 100, replace = T)
y_jiayin <- sample(c(1,0), 100, replace = T)
y_peiqing <- sample(c(1,0), 100, replace = T)
y_steve <- sample(c(1,0), 100, replace = T)
y_mei <- sample(c(1,0), 100, replace = T)
y_jiayin <- sample(c(1,0), 100, replace = T)
y_peiqing <- sample(c(1,0), 100, replace = T)
y_steve <- sample(c(1,0), 100, replace = T)
y_mei <- sample(c(1,0), 100, replace = T)
y_yun <- sample(c(1,0), 100, replace = T)
y_yun
group_members <- c("jiayin", "peiqing", "steve", "mei", "yun")
purrr::map_dfc(.x = group_members, mutate(!!.x = sample(c(1, 0), 10, replace = T)))
purrr::map_dfc(.x = group_members, ~ mutate(!!.x = sample(c(1, 0), 10, replace = T)))
purrr::map_dfc(.x = group_members, ~ sample(c(1, 0), 10, replace = T)))
purrr::map_dfc(.x = group_members, ~ sample(c(1, 0), 10, replace = T))
purrr::map_dfc(.x = group_members, ~ .x =  sample(c(1, 0), 10, replace = T))
purrr::map_dfc(.x = group_members, ~ !!.x =  sample(c(1, 0), 10, replace = T))
purrr::map_dfc(.x = group_members, ~ !!.x =  sample(c(1, 0), 10, replace = T), .id = !!.x)
purrr::map_dfc(.x = group_members, ~  sample(c(1, 0), 10, replace = T), .id = !!.x)
?map_dfc
purrr::map_dfr(.x = group_members, ~  sample(c(1, 0), 10, replace = T), .id = !!.x)
purrr::map_dfr(.x = group_members, ~  sample(c(1, 0), 10, replace = T), .id = "y_output")
purrr::map_dfr(.x = group_members, ~  sample(c(1, 0), 10, replace = T), .id = "y_output")
purrr::map_dfc(.x = group_members, ~  tibble(!!.x := sample(c(1, 0), 10, replace = T)))
(purrr::map_dfc(.x = group_members, ~  tibble(!!.x := sample(c(1, 0), 10, replace = T))))
(purrr::map_dfc(.x = group_members, ~  tibble(!!.x := sample(c(1, 0), 100, replace = T))))
y_predictions <- (purrr::map_dfc(.x = group_members, ~  tibble(!!.x := sample(c(1, 0), 100, replace = T))))
(y_predictions <- purrr::map_dfc(.x = group_members, ~  tibble(!!.x := sample(c(1, 0), 100, replace = T))))
y_predictions
# Ensemble example
library(tidyverse)
y_predictions %>% rowwise() %>% mutate(total = mean(everything()))
y_predictions %>% rowwise() %>% mutate(total = mean(everything()))
y_predictions %>% rowwise() %>% mutate(total = mean(.x))
y_predictions %>% rowwise() %>% mutate(total = mean(.))
y_predictions %>% rowwise() %>% mutate(total = mean(jiayin:yun))
# Get rowwise mean
(y_predictions <- y_predictions %>% rowwise() %>% mutate(total = if_else(mean(jiayin:yun) > 0.5, 1, 0))
# Get rowwise mean
(y_predictions <- y_predictions %>% rowwise() %>% mutate(total = if_else(mean(jiayin:yun) > 0.5, 1, 0))
)
# Get rowwise mean
(y_predictions <- y_predictions %>% rowwise() %>% mutate(total = if_else(mean(jiayin:yun) > 0.5, 1, 0))
)
y_predictions
